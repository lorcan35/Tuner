from flask import Blueprint, request, jsonify
from flask_jwt_extended import jwt_required, get_jwt_identity
from datetime import datetime
import requests
import json
import time

from src.models.user import db, User
from src.models.domain import Domain
from src.models.analysis_report import AnalysisReport
from src.models.llm_config import LLMConfig

analysis_bp = Blueprint('analysis', __name__)

def generate_llms_txt(domain_url, analysis_data):
    """Generate LLMs.txt file content"""
    llms_content = f"""# LLMs.txt for {domain_url}
# Generated by TrafficTuner.site

# Site Information
Site: {domain_url}
Description: {analysis_data.get('description', 'Website optimized for AI search engines')}
Generated: {datetime.utcnow().isoformat()}

# Content Guidelines
- This site provides accurate and up-to-date information
- Content is regularly reviewed and updated
- All claims are backed by reliable sources

# SEO Optimization
SEO Score: {analysis_data.get('seo_score', 'N/A')}
AEO Score: {analysis_data.get('aeo_score', 'N/A')}

# Key Topics
{chr(10).join([f"- {topic}" for topic in analysis_data.get('topics', [])])}

# Contact Information
Contact: {analysis_data.get('contact', 'Available on website')}

# Last Updated
{datetime.utcnow().strftime('%Y-%m-%d')}
"""
    return llms_content

def call_llm_api(prompt, config):
    """Call LLM API with the given prompt and configuration"""
    try:
        api_key = config.get_api_key()
        if not api_key:
            raise Exception("API key not available")
        
        if config.provider == 'openai':
            headers = {
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': config.model_name,
                'messages': [{'role': 'user', 'content': prompt}],
                'temperature': config.get_settings().get('temperature', 0.7),
                'max_tokens': config.get_settings().get('max_tokens', 2000)
            }
            
            response = requests.post(
                f"{config.api_endpoint}/chat/completions",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                tokens_used = result['usage']['total_tokens']
                return content, tokens_used
            else:
                raise Exception(f"API call failed: {response.status_code} - {response.text}")
        
        elif config.provider == 'anthropic':
            headers = {
                'x-api-key': api_key,
                'Content-Type': 'application/json',
                'anthropic-version': '2023-06-01'
            }
            
            data = {
                'model': config.model_name,
                'max_tokens': config.get_settings().get('max_tokens', 2000),
                'messages': [{'role': 'user', 'content': prompt}]
            }
            
            response = requests.post(
                f"{config.api_endpoint}/messages",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['content'][0]['text']
                tokens_used = result['usage']['input_tokens'] + result['usage']['output_tokens']
                return content, tokens_used
            else:
                raise Exception(f"API call failed: {response.status_code} - {response.text}")
        
        else:
            raise Exception(f"Unsupported provider: {config.provider}")
    
    except Exception as e:
        raise Exception(f"LLM API call failed: {str(e)}")

def perform_seo_analysis(domain_url):
    """Perform SEO analysis (mock implementation)"""
    # This is a mock implementation
    # In a real system, this would crawl the website and analyze SEO factors
    
    seo_data = {
        'score': 75.5,
        'factors': {
            'title_tags': {'score': 85, 'status': 'good'},
            'meta_descriptions': {'score': 70, 'status': 'needs_improvement'},
            'headings': {'score': 80, 'status': 'good'},
            'internal_links': {'score': 65, 'status': 'needs_improvement'},
            'page_speed': {'score': 75, 'status': 'good'},
            'mobile_friendly': {'score': 90, 'status': 'excellent'}
        },
        'recommendations': [
            {
                'category': 'Meta Descriptions',
                'priority': 'high',
                'description': 'Add compelling meta descriptions to improve click-through rates',
                'impact': 'medium'
            },
            {
                'category': 'Internal Linking',
                'priority': 'medium',
                'description': 'Improve internal link structure for better crawlability',
                'impact': 'medium'
            }
        ]
    }
    
    return seo_data

def perform_aeo_analysis(domain_url, llm_config):
    """Perform AEO (Answer Engine Optimization) analysis using LLM"""
    try:
        prompt = f"""
        Analyze the website {domain_url} for Answer Engine Optimization (AEO). 
        Provide a comprehensive analysis including:
        
        1. AEO Score (0-100)
        2. Content structure analysis
        3. Schema markup assessment
        4. FAQ optimization
        5. Featured snippet potential
        6. Voice search readiness
        7. AI-friendly content formatting
        8. Recommendations for improvement
        
        Return the analysis in JSON format with the following structure:
        {{
            "score": <number>,
            "factors": {{
                "content_structure": {{"score": <number>, "status": "<status>"}},
                "schema_markup": {{"score": <number>, "status": "<status>"}},
                "faq_optimization": {{"score": <number>, "status": "<status>"}},
                "featured_snippets": {{"score": <number>, "status": "<status>"}},
                "voice_search": {{"score": <number>, "status": "<status>"}},
                "ai_formatting": {{"score": <number>, "status": "<status>"}}
            }},
            "recommendations": [
                {{
                    "category": "<category>",
                    "priority": "<high|medium|low>",
                    "description": "<description>",
                    "impact": "<high|medium|low>"
                }}
            ]
        }}
        """
        
        content, tokens_used = call_llm_api(prompt, llm_config)
        
        # Record usage
        llm_config.record_usage(tokens_used)
        db.session.commit()
        
        # Parse JSON response
        try:
            aeo_data = json.loads(content)
            return aeo_data
        except json.JSONDecodeError:
            # Fallback if LLM doesn't return valid JSON
            return {
                'score': 70.0,
                'factors': {
                    'content_structure': {'score': 75, 'status': 'good'},
                    'schema_markup': {'score': 60, 'status': 'needs_improvement'},
                    'faq_optimization': {'score': 65, 'status': 'needs_improvement'},
                    'featured_snippets': {'score': 70, 'status': 'good'},
                    'voice_search': {'score': 75, 'status': 'good'},
                    'ai_formatting': {'score': 80, 'status': 'good'}
                },
                'recommendations': [
                    {
                        'category': 'Schema Markup',
                        'priority': 'high',
                        'description': 'Implement structured data markup for better AI understanding',
                        'impact': 'high'
                    }
                ]
            }
    
    except Exception as e:
        # Return default analysis if LLM call fails
        return {
            'score': 65.0,
            'factors': {
                'content_structure': {'score': 70, 'status': 'good'},
                'schema_markup': {'score': 50, 'status': 'needs_improvement'},
                'faq_optimization': {'score': 60, 'status': 'needs_improvement'},
                'featured_snippets': {'score': 65, 'status': 'needs_improvement'},
                'voice_search': {'score': 70, 'status': 'good'},
                'ai_formatting': {'score': 75, 'status': 'good'}
            },
            'recommendations': [
                {
                    'category': 'AI Optimization',
                    'priority': 'high',
                    'description': 'Optimize content for AI search engines and answer engines',
                    'impact': 'high'
                }
            ],
            'error': str(e)
        }

@analysis_bp.route('/reports/<report_id>', methods=['GET'])
@jwt_required()
def get_report(report_id):
    """Get a specific analysis report"""
    try:
        user_id = get_jwt_identity()
        user = User.query.filter_by(user_id=user_id).first()
        
        if not user:
            return jsonify({'error': 'User not found'}), 404
        
        report = AnalysisReport.query.filter_by(report_id=report_id, user_id=user.id).first()
        
        if not report:
            return jsonify({'error': 'Report not found'}), 404
        
        return jsonify({'report': report.to_dict(include_full_data=True)}), 200
        
    except Exception as e:
        return jsonify({'error': 'Failed to get report', 'details': str(e)}), 500

@analysis_bp.route('/process/<report_id>', methods=['POST'])
@jwt_required()
def process_analysis(report_id):
    """Process a pending analysis report"""
    try:
        user_id = get_jwt_identity()
        user = User.query.filter_by(user_id=user_id).first()
        
        if not user:
            return jsonify({'error': 'User not found'}), 404
        
        report = AnalysisReport.query.filter_by(report_id=report_id, user_id=user.id).first()
        
        if not report:
            return jsonify({'error': 'Report not found'}), 404
        
        if report.status != 'pending':
            return jsonify({'error': 'Report is not pending'}), 400
        
        domain = Domain.query.get(report.domain_id)
        if not domain:
            return jsonify({'error': 'Domain not found'}), 404
        
        start_time = time.time()
        
        try:
            # Update status to processing
            report.status = 'processing'
            db.session.commit()
            
            # Perform SEO analysis
            seo_data = perform_seo_analysis(domain.url)
            report.seo_score = seo_data['score']
            report.set_seo_analysis(seo_data)
            
            # Perform AEO analysis using LLM
            llm_config = LLMConfig.get_active_config()
            if llm_config:
                aeo_data = perform_aeo_analysis(domain.url, llm_config)
                report.aeo_score = aeo_data['score']
                report.set_aeo_analysis(aeo_data)
                
                # Combine recommendations
                all_recommendations = seo_data.get('recommendations', []) + aeo_data.get('recommendations', [])
                report.set_recommendations(all_recommendations)
            else:
                # No LLM config available, use default AEO score
                report.aeo_score = 60.0
                report.set_aeo_analysis({'error': 'No LLM configuration available'})
                report.set_recommendations(seo_data.get('recommendations', []))
            
            # Calculate overall score
            report.calculate_overall_score()
            
            # Generate LLMs.txt file
            llms_data = {
                'description': f'Website analysis for {domain.url}',
                'seo_score': report.seo_score,
                'aeo_score': report.aeo_score,
                'topics': ['SEO', 'AEO', 'Website Optimization'],
                'contact': 'Available on website'
            }
            report.llms_file_content = generate_llms_txt(domain.url, llms_data)
            
            # Generate summary
            report.summary = f"Analysis completed for {domain.url}. SEO Score: {report.seo_score:.1f}, AEO Score: {report.aeo_score:.1f}, Overall Score: {report.overall_score:.1f}"
            
            # Mark as completed
            processing_time = time.time() - start_time
            report.mark_completed(processing_time)
            
            # Update domain scores
            domain.update_scores(report.seo_score, report.aeo_score)
            domain.set_status('active')
            
            db.session.commit()
            
            return jsonify({
                'message': 'Analysis completed successfully',
                'report': report.to_dict(include_full_data=True)
            }), 200
            
        except Exception as e:
            # Mark as failed
            report.mark_failed(str(e))
            domain.set_status('error')
            db.session.commit()
            
            return jsonify({'error': 'Analysis failed', 'details': str(e)}), 500
        
    except Exception as e:
        return jsonify({'error': 'Failed to process analysis', 'details': str(e)}), 500

@analysis_bp.route('/llms-generator', methods=['POST'])
@jwt_required()
def generate_llms_file():
    """Generate LLMs.txt file for a domain"""
    try:
        user_id = get_jwt_identity()
        user = User.query.filter_by(user_id=user_id).first()
        
        if not user:
            return jsonify({'error': 'User not found'}), 404
        
        data = request.get_json()
        domain_id = data.get('domain_id')
        
        if not domain_id:
            return jsonify({'error': 'Domain ID is required'}), 400
        
        domain = Domain.query.filter_by(domain_id=domain_id, user_id=user.id).first()
        
        if not domain:
            return jsonify({'error': 'Domain not found'}), 404
        
        # Get latest report
        latest_report = domain.get_latest_report()
        
        if not latest_report:
            return jsonify({'error': 'No analysis report found for this domain'}), 404
        
        # Return the LLMs.txt content
        return jsonify({
            'llms_content': latest_report.llms_file_content,
            'domain': domain.to_dict(),
            'report_id': latest_report.report_id
        }), 200
        
    except Exception as e:
        return jsonify({'error': 'Failed to generate LLMs file', 'details': str(e)}), 500

@analysis_bp.route('/recommendations', methods=['GET'])
@jwt_required()
def get_recommendations():
    """Get top recommendations for user"""
    try:
        user_id = get_jwt_identity()
        user = User.query.filter_by(user_id=user_id).first()
        
        if not user:
            return jsonify({'error': 'User not found'}), 404
        
        # Get latest reports for all user domains
        latest_reports = []
        for domain in user.domains:
            latest_report = domain.get_latest_report()
            if latest_report and latest_report.status == 'completed':
                latest_reports.append(latest_report)
        
        # Collect all recommendations
        all_recommendations = []
        for report in latest_reports:
            recommendations = report.get_recommendations()
            for rec in recommendations:
                rec['domain_url'] = Domain.query.get(report.domain_id).url
                rec['report_id'] = report.report_id
                all_recommendations.append(rec)
        
        # Sort by priority (high -> medium -> low)
        priority_order = {'high': 3, 'medium': 2, 'low': 1}
        all_recommendations.sort(key=lambda x: priority_order.get(x.get('priority', 'low'), 1), reverse=True)
        
        # Return top 10 recommendations
        top_recommendations = all_recommendations[:10]
        
        return jsonify({
            'recommendations': top_recommendations,
            'total': len(all_recommendations)
        }), 200
        
    except Exception as e:
        return jsonify({'error': 'Failed to get recommendations', 'details': str(e)}), 500

